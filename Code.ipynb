{
 "cells": [
  {
   "cell_type": "raw",
   "id": "a604e3e9",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: STATS/CSE 780 - Homework Assignment 2\n",
    "author: \"Name: Amanpreet Singh (400672477)\"\n",
    "date: 2025/09/30\n",
    "format: pdf\n",
    "header-includes:\n",
    "   - \\usepackage{amsmath}\n",
    "   - \\usepackage{bbm}\n",
    "   - \\usepackage{array}\n",
    "   - \\usepackage{multirow}\n",
    "   - \\usepackage{graphicx}\n",
    "   - \\usepackage{float}\n",
    "   - \\usepackage{apacite}\n",
    "   - \\newcommand{\\bc}{\\color{black}}\n",
    "   - \\newcommand{\\blc}{\\color{blue}}\n",
    "   - \\newcommand{\\mX}{\\mbox{\\textbf{X}}}\n",
    "execute: \n",
    "  echo: true \n",
    "fontsize: 9pt\n",
    "geometry: margin = 1in\n",
    "linestretch: 1.5\n",
    "bibliography: STATS780.bib \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69ea892",
   "metadata": {},
   "source": [
    "\\newpage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94c974b",
   "metadata": {},
   "source": [
    "# Supplemental Material\n",
    "\n",
    "- Note: GitHub Copilot was used to assist with code generation and error handling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0041e988",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7cc2d41a",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "::: {.grid}\n",
    "::: {.g-col-6}\n",
    "![](plots/corr.png){fig-align=\"left\" width=\"40%\"}\n",
    "![](plots/pie.png){fig-align=\"right\" width=\"40%\"}\n",
    ":::\n",
    "\n",
    "::: {.grid}\n",
    "::: {.g-col-6}\n",
    "![](plots/LMNN.png){fig-align=\"left\" width=\"40%\"}\n",
    "![](plots/KNN.png){fig-align=\"right\" width=\"40%\"}\n",
    "![](plots/LR.png){fig-align=\"right\" width=\"40%\"}\n",
    "![](plots/LR_C.png){fig-align=\"right\" width=\"40%\"}\n",
    ":::\n",
    "\n",
    "::: {.grid}\n",
    "::: {.g-col-6}\n",
    "![](plots/boxplot.png){fig-align=\"center\" width=\"100%\"}\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109771b4",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4253ca61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Preprocessing & Splitting\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from metric_learn import LMNN  # Metric learning, optional\n",
    "\n",
    "# Metrics & Evaluation\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    roc_curve,\n",
    "    roc_auc_score\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19d52887",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"spotify_churn_dataset.csv\")\n",
    "df = df.drop(columns=['user_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbce5b71",
   "metadata": {},
   "source": [
    "# Exploratory Data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f38a3e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8000 entries, 0 to 7999\n",
      "Data columns (total 11 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   gender                 8000 non-null   object \n",
      " 1   age                    8000 non-null   int64  \n",
      " 2   country                8000 non-null   object \n",
      " 3   subscription_type      8000 non-null   object \n",
      " 4   listening_time         8000 non-null   int64  \n",
      " 5   songs_played_per_day   8000 non-null   int64  \n",
      " 6   skip_rate              8000 non-null   float64\n",
      " 7   device_type            8000 non-null   object \n",
      " 8   ads_listened_per_week  8000 non-null   int64  \n",
      " 9   offline_listening      8000 non-null   int64  \n",
      " 10  is_churned             8000 non-null   int64  \n",
      "dtypes: float64(1), int64(6), object(4)\n",
      "memory usage: 687.6+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>listening_time</th>\n",
       "      <th>songs_played_per_day</th>\n",
       "      <th>skip_rate</th>\n",
       "      <th>ads_listened_per_week</th>\n",
       "      <th>offline_listening</th>\n",
       "      <th>is_churned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>37.662125</td>\n",
       "      <td>154.068250</td>\n",
       "      <td>50.127250</td>\n",
       "      <td>0.300127</td>\n",
       "      <td>6.943875</td>\n",
       "      <td>0.747750</td>\n",
       "      <td>0.258875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12.740359</td>\n",
       "      <td>84.015596</td>\n",
       "      <td>28.449762</td>\n",
       "      <td>0.173594</td>\n",
       "      <td>13.617953</td>\n",
       "      <td>0.434331</td>\n",
       "      <td>0.438044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>16.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>26.000000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>38.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>49.000000</td>\n",
       "      <td>227.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>59.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               age  listening_time  songs_played_per_day    skip_rate  \\\n",
       "count  8000.000000     8000.000000           8000.000000  8000.000000   \n",
       "mean     37.662125      154.068250             50.127250     0.300127   \n",
       "std      12.740359       84.015596             28.449762     0.173594   \n",
       "min      16.000000       10.000000              1.000000     0.000000   \n",
       "25%      26.000000       81.000000             25.000000     0.150000   \n",
       "50%      38.000000      154.000000             50.000000     0.300000   \n",
       "75%      49.000000      227.000000             75.000000     0.450000   \n",
       "max      59.000000      299.000000             99.000000     0.600000   \n",
       "\n",
       "       ads_listened_per_week  offline_listening   is_churned  \n",
       "count            8000.000000        8000.000000  8000.000000  \n",
       "mean                6.943875           0.747750     0.258875  \n",
       "std                13.617953           0.434331     0.438044  \n",
       "min                 0.000000           0.000000     0.000000  \n",
       "25%                 0.000000           0.000000     0.000000  \n",
       "50%                 0.000000           1.000000     0.000000  \n",
       "75%                 5.000000           1.000000     1.000000  \n",
       "max                49.000000           1.000000     1.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()\n",
    "df.shape\n",
    "df.info()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ddfaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select categorical columns\n",
    "categorical_cols = df.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "# Plot pie charts in 2x2 grids\n",
    "for i in range(0, len(categorical_cols), 4):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    for j, col in enumerate(categorical_cols[i:i+4], 1):\n",
    "        plt.subplot(2, 2, j)\n",
    "        df[col].value_counts().plot(\n",
    "            kind='pie',\n",
    "            autopct='%1.1f%%',\n",
    "            startangle=90,\n",
    "            colors=sns.color_palette(\"pastel\"),\n",
    "            wedgeprops={'edgecolor': 'k'}\n",
    "        )\n",
    "        plt.title(col.replace(\"_\", \" \").title(), fontsize=10)\n",
    "        plt.ylabel('')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"pie.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6bb50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(df.corr(numeric_only=True), annot=True, cmap=\"coolwarm\")\n",
    "plt.title(\"Correlation Heatmap (Numerical Variables)\")\n",
    "plt.savefig(\"corr.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a40f2c64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values Summary:\n",
      "\n",
      "gender                   0\n",
      "age                      0\n",
      "country                  0\n",
      "subscription_type        0\n",
      "listening_time           0\n",
      "songs_played_per_day     0\n",
      "skip_rate                0\n",
      "device_type              0\n",
      "ads_listened_per_week    0\n",
      "offline_listening        0\n",
      "is_churned               0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# ----- Missing Values -----\n",
    "print(\"Missing Values Summary:\\n\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d9d6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Boxplots for Outliers -----\n",
    "# Select only numeric columns\n",
    "numeric_cols = df.select_dtypes(include=['number']).columns\n",
    "\n",
    "# Create boxplots for each numeric column\n",
    "plt.figure(figsize=(15, 8))\n",
    "for i, col in enumerate(numeric_cols, 1):\n",
    "    plt.subplot((len(numeric_cols) + 2)//3, 3, i)\n",
    "    sns.boxplot(x=df[col], color='skyblue')\n",
    "    plt.title(col)\n",
    "    plt.tight_layout()\n",
    "\n",
    "plt.suptitle(\"Boxplots for Numeric Features\", fontsize=16, y=1.03)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4a3d1d",
   "metadata": {},
   "source": [
    "# Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d860dfee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (8000, 10)\n",
      "y shape: (8000,)\n"
     ]
    }
   ],
   "source": [
    "y = df['is_churned']\n",
    "\n",
    "# Features: drop the target\n",
    "X = df.drop(columns=['is_churned'])\n",
    "\n",
    "# Optional: check the shapes\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eebb4c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size: 4800\n",
      "Validation size: 1600\n",
      "Test size: 1600\n"
     ]
    }
   ],
   "source": [
    "# First, spliting off the test set (20%)\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Then, spliting the remaining 80% into training and validation (75% train, 25% val → 60/20 overall)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.25, random_state=42, stratify=y_temp\n",
    ")\n",
    "\n",
    "print(\"Training size:\", X_train.shape[0])\n",
    "print(\"Validation size:\", X_val.shape[0])\n",
    "print(\"Test size:\", X_test.shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623c43aa",
   "metadata": {},
   "source": [
    "# Scalling and Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b78f70b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (4800, 24)\n",
      "X_val: (1600, 24)\n",
      "X_test: (1600, 24)\n"
     ]
    }
   ],
   "source": [
    "# 3. One-hot encode categorical variables directly (returns DataFrame)\n",
    "X_train_final = pd.get_dummies(X_train, dtype=int, columns=X_train.select_dtypes\n",
    "                               (include=['object']).columns, drop_first=False)\n",
    "X_val_final = pd.get_dummies(X_val, dtype=int,columns=X_val.select_dtypes\n",
    "                             (include=['object']).columns, drop_first=False)\n",
    "X_test_final = pd.get_dummies(X_test, dtype=int,columns=X_test.select_dtypes\n",
    "                              (include=['object']).columns, drop_first=False)\n",
    "\n",
    "# 4. Align columns (in case some categories are missing in val/test)\n",
    "X_val_final = X_val_final.reindex(columns=X_train_final.columns, fill_value=0)\n",
    "X_test_final = X_test_final.reindex(columns=X_train_final.columns, fill_value=0)\n",
    "\n",
    "# 5. Shapes\n",
    "print(\"X_train:\", X_train_final.shape)\n",
    "print(\"X_val:\", X_val_final.shape)\n",
    "print(\"X_test:\", X_test_final.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9dd7336d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns you want to scale\n",
    "scale_cols = ['age', 'listening_time', 'songs_played_per_day', 'skip_rate']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Copy so we don't overwrite original data\n",
    "X_train_scaled = X_train_final.copy()\n",
    "X_val_scaled   = X_val_final.copy()\n",
    "X_test_scaled  = X_test_final.copy()\n",
    "\n",
    "# Fit on train only\n",
    "X_train_scaled[scale_cols] = scaler.fit_transform(X_train_final[scale_cols])\n",
    "X_val_scaled[scale_cols]   = scaler.transform(X_val_final[scale_cols])\n",
    "X_test_scaled[scale_cols]  = scaler.transform(X_test_final[scale_cols])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d5cef7",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ff8dabc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best k based on validation set: 17\n"
     ]
    }
   ],
   "source": [
    "# Range of k values to try\n",
    "k_values = range(1, 21)  # try k from 1 to 20\n",
    "val_accuracies = []\n",
    "\n",
    "for k in k_values:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train_scaled, y_train)\n",
    "    y_val_pred = knn.predict(X_val_scaled)\n",
    "    acc = accuracy_score(y_val, y_val_pred)\n",
    "    val_accuracies.append(acc)\n",
    "\n",
    "# Find best k\n",
    "best_k = k_values[np.argmax(val_accuracies)]\n",
    "print(\"Best k based on validation set:\", best_k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9295b726",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(k_values, val_accuracies, marker='o')\n",
    "plt.xlabel(\"Number of Neighbors (k)\")\n",
    "plt.ylabel(\"Validation Accuracy\")\n",
    "plt.title(\"Choosing k using Validation Set\")\n",
    "plt.xticks(k_values)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49ab631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Train best KNN on combined train+val and test it ---\n",
    "best_k = 14  # selected from validation performance\n",
    "knn = KNeighborsClassifier(n_neighbors=best_k)\n",
    "knn.fit(np.vstack((X_train_scaled, X_val_scaled)), np.hstack((y_train, y_val)))\n",
    "y_test_prob = knn.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# --- ROC and optimal cutoff ---\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_test_prob)\n",
    "optimal_idx = (tpr - fpr).argmax()\n",
    "optimal_cutoff = thresholds[optimal_idx]\n",
    "print(f\"Optimal probability cutoff: {optimal_cutoff:.3f}\")\n",
    "\n",
    "# --- Plot ROC curve ---\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {roc_auc_score(y_test, y_test_prob):.3f})', color='blue')\n",
    "plt.plot([0, 1], [0, 1], '--', color='gray', label='Random Guess')\n",
    "plt.scatter(fpr[optimal_idx], tpr[optimal_idx], color='red', label=f'Optimal cutoff = {optimal_cutoff:.2f}')\n",
    "plt.title(\"KNN ROC Curve with Optimal Cutoff\")\n",
    "plt.xlabel(\"1 - Specificity (False Positive Rate)\")\n",
    "plt.ylabel(\"Sensitivity (True Positive Rate)\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# --- Apply optimal cutoff and compute metrics ---\n",
    "y_test_pred = (y_test_prob >= optimal_cutoff).astype(int)\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "precision = precision_score(y_test, y_test_pred)\n",
    "misclassification_error = 1 - accuracy\n",
    "recall = recall_score(y_test, y_test_pred)  # Sensitivity\n",
    "specificity = tn / (tn + fp)\n",
    "f1 = f1_score(y_test, y_test_pred)\n",
    "auc = roc_auc_score(y_test, y_test_prob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "201693a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.499\n",
      "Precision: 0.274\n",
      "Misclassification Error: 0.501\n",
      "Sensitivity (Recall): 0.565\n",
      "Specificity: 0.476\n",
      "F1-Score: 0.369\n",
      "AUC: 0.522\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nAccuracy: {accuracy:.3f}\")\n",
    "print(f\"Precision: {precision:.3f}\")\n",
    "print(f\"Misclassification Error: {misclassification_error:.3f}\")\n",
    "print(f\"Sensitivity (Recall): {recall:.3f}\")\n",
    "print(f\"Specificity: {specificity:.3f}\")\n",
    "print(f\"F1-Score: {f1:.3f}\")\n",
    "print(f\"AUC: {auc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90c64e6",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15742e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best C (acc): 0.1 0.5225\n",
      "Best C (f1): 0.00046415888336127773 0.35294117647058826\n",
      "Best C (auc): 1.0 0.5150345007372649\n"
     ]
    }
   ],
   "source": [
    "C_values = np.logspace(-4, 4, 25)\n",
    "accs, f1s, aucs = [], [], []\n",
    "\n",
    "for C in C_values:\n",
    "    clf = LogisticRegression(C=C, solver='liblinear', class_weight='balanced', max_iter=1000)\n",
    "    clf.fit(X_train_scaled, y_train)\n",
    "    y_val_prob = clf.predict_proba(X_val_scaled)[:,1]  # if binary\n",
    "    y_val_pred = (y_val_prob >= 0.5).astype(int)\n",
    "\n",
    "    accs.append(accuracy_score(y_val, y_val_pred))\n",
    "    f1s.append(f1_score(y_val, y_val_pred, average='binary'))  # change average for multiclass\n",
    "    try:\n",
    "        aucs.append(roc_auc_score(y_val, y_val_prob))\n",
    "    except Exception:\n",
    "        aucs.append(np.nan)\n",
    "\n",
    "# report best by different metrics\n",
    "best_acc = C_values[np.nanargmax(accs)]\n",
    "best_f1  = C_values[np.nanargmax(f1s)]\n",
    "best_auc = C_values[np.nanargmax(aucs)]\n",
    "\n",
    "print(\"Best C (acc):\", best_acc, max(accs))\n",
    "print(\"Best C (f1):\", best_f1, max(f1s))\n",
    "print(\"Best C (auc):\", best_auc, max(aucs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7430ddbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.semilogx(C_values, aucs, marker='o')\n",
    "plt.xlabel(\"Regularization Strength (C)\")\n",
    "plt.ylabel(\"AUC\")\n",
    "plt.title(\"Choosing C for Logistic Regression\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974983a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a final model (use best C or just C=1)\n",
    "clf = LogisticRegression(C=1, solver='liblinear', class_weight='balanced', max_iter=1000)\n",
    "clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict probabilities on validation or test set\n",
    "y_test_prob = clf.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Compute ROC curve values\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_test_prob)\n",
    "auc = roc_auc_score(y_test, y_test_prob)\n",
    "\n",
    "# Find optimal cutoff index\n",
    "optimal_idx = (tpr - fpr).argmax()\n",
    "optimal_cutoff = thresholds[optimal_idx]\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC Curve (AUC = {auc:.3f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--', label='Random Guess')\n",
    "\n",
    "# Mark optimal point\n",
    "plt.scatter(fpr[optimal_idx], tpr[optimal_idx], color='red', s=80,\n",
    "            label=f'Optimal cutoff = {optimal_cutoff:.2f}')\n",
    "\n",
    "# Labels and legend\n",
    "plt.xlabel('1 - Specificity (False Positive Rate)')\n",
    "plt.ylabel('Sensitivity (True Positive Rate)')\n",
    "plt.title('ROC Curve with Optimal Cutoff')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Classify based on cutoff\n",
    "y_test_pred = (y_test_prob >= 0.49).astype(int)\n",
    "\n",
    "# Confusion matrix and performance metrics\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_test_pred)\n",
    "error_rate = 1 - accuracy\n",
    "sensitivity = tp / (tp + fn)\n",
    "specificity = tn / (tn + fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b29b4b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Logistic Regression Test Performance ===\n",
      "Accuracy: 0.459\n",
      "Misclassification Error: 0.541\n",
      "Sensitivity (TPR): 0.589\n",
      "Specificity (TNR): 0.414\n",
      "Confusion Matrix:\n",
      " [[491 695]\n",
      " [170 244]]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Logistic Regression Test Performance ===\")\n",
    "print(f\"Accuracy: {accuracy:.3f}\")\n",
    "print(f\"Misclassification Error: {error_rate:.3f}\")\n",
    "print(f\"Sensitivity (TPR): {sensitivity:.3f}\")\n",
    "print(f\"Specificity (TNR): {specificity:.3f}\")\n",
    "print(\"Confusion Matrix:\\n\", cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9c807e4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Coefficient</th>\n",
       "      <th>AbsCoefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>country_CA</td>\n",
       "      <td>-0.165776</td>\n",
       "      <td>0.165776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>subscription_type_Free</td>\n",
       "      <td>-0.144746</td>\n",
       "      <td>0.144746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>country_FR</td>\n",
       "      <td>0.135067</td>\n",
       "      <td>0.135067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Feature  Coefficient  AbsCoefficient\n",
       "10              country_CA    -0.165776        0.165776\n",
       "18  subscription_type_Free    -0.144746        0.144746\n",
       "12              country_FR     0.135067        0.135067"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_df = pd.DataFrame({\n",
    "    'Feature': X_train_scaled.columns,\n",
    "    'Coefficient': clf.coef_.ravel()\n",
    "})\n",
    "coef_df['AbsCoefficient'] = np.abs(coef_df['Coefficient'])\n",
    "coef_df.sort_values('AbsCoefficient', ascending=False)[0:3]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ee3429",
   "metadata": {},
   "source": [
    "# KNN using LMNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090a20d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train LMNN on training data ---\n",
    "lmnn = LMNN(k=5, learn_rate=1e-6, max_iter=200)\n",
    "lmnn.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Transform train, val, test sets ---\n",
    "X_train_lmnn = lmnn.transform(X_train_scaled)\n",
    "X_val_lmnn   = lmnn.transform(X_val_scaled)\n",
    "X_test_lmnn  = lmnn.transform(X_test_scaled)\n",
    "\n",
    "# Select best k using validation accuracy ---\n",
    "k_values = range(1, 21)\n",
    "val_accuracies = []\n",
    "\n",
    "for k in k_values:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train_lmnn, y_train)\n",
    "    y_val_pred = knn.predict(X_val_lmnn)\n",
    "    acc = accuracy_score(y_val, y_val_pred)\n",
    "    val_accuracies.append(acc)\n",
    "\n",
    "best_k = k_values[np.argmax(val_accuracies)]\n",
    "print(\"Best k (with LMNN) based on validation set:\", best_k)\n",
    "\n",
    "# Plot validation accuracy vs k ---\n",
    "plt.plot(k_values, val_accuracies, marker='o')\n",
    "plt.xlabel(\"Number of Neighbors (k)\")\n",
    "plt.ylabel(\"Validation Accuracy (LMNN)\")\n",
    "plt.title(\"Choosing k using Validation Set (after LMNN)\")\n",
    "plt.xticks(k_values)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9bc1515d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC (LMNN + KNN): 0.524\n",
      "Optimal probability cutoff: 0.333\n",
      "Confusion Matrix (LMNN + KNN):\n",
      "[[723 463]\n",
      " [232 182]]\n",
      "\n",
      "Accuracy: 0.566\n",
      "Misclassification Error: 0.434\n",
      "Precision: 0.282\n",
      "Sensitivity (Recall): 0.440\n",
      "Specificity: 0.610\n",
      "F1-Score: 0.344\n",
      "AUC: 0.524\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train final KNN (best_k) on combined train+val and test it ---\n",
    "knn = KNeighborsClassifier(n_neighbors=12)\n",
    "knn.fit(np.vstack((X_train_lmnn, X_val_lmnn)), np.hstack((y_train, y_val)))\n",
    "\n",
    "# Predict probabilities on test set ---\n",
    "y_test_prob = knn.predict_proba(X_test_lmnn)[:, 1]\n",
    "\n",
    "# ROC curve and optimal cutoff ---\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_test_prob)\n",
    "auc = roc_auc_score(y_test, y_test_prob)\n",
    "optimal_idx = (tpr - fpr).argmax()\n",
    "optimal_cutoff = thresholds[optimal_idx]\n",
    "print(f\"AUC (LMNN + KNN): {auc:.3f}\")\n",
    "print(f\"Optimal probability cutoff: {optimal_cutoff:.3f}\")\n",
    "\n",
    "# Confusion matrix using optimal cutoff ---\n",
    "y_test_pred = (y_test_prob >= optimal_cutoff).astype(int)\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "print(\"Confusion Matrix (LMNN + KNN):\")\n",
    "print(cm)\n",
    "\n",
    "# Compute performance metrics ---\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "misclassification_error = 1 - accuracy\n",
    "precision = tp / (tp + fp) if (tp + fp) != 0 else 0\n",
    "recall = tp / (tp + fn) if (tp + fn) != 0 else 0  # Sensitivity\n",
    "specificity = tn / (tn + fp) if (tn + fp) != 0 else 0\n",
    "f1_score_val = 2 * (precision * recall) / (precision + recall) if (precision + recall) != 0 else 0\n",
    "auc_val = roc_auc_score(y_test, y_test_prob)\n",
    "\n",
    "# Print metrics ---\n",
    "print(f\"\\nAccuracy: {accuracy:.3f}\")\n",
    "print(f\"Misclassification Error: {misclassification_error:.3f}\")\n",
    "print(f\"Precision: {precision:.3f}\")\n",
    "print(f\"Sensitivity (Recall): {recall:.3f}\")\n",
    "print(f\"Specificity: {specificity:.3f}\")\n",
    "print(f\"F1-Score: {f1_score_val:.3f}\")\n",
    "print(f\"AUC: {auc_val:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
